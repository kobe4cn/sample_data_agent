# 结构化文件分析引导系统 - 技术设计

## Context

当前系统通过 `prompt.py` 提供数据预处理指导，但这些指导是平铺式的代码示例，缺乏系统化的思维框架。用户报告在处理复杂 Excel 文件时：

1. 模型经常跳过文件结构检查，直接猜测列名导致失败
2. 多次迭代才能正确识别多层表头位置
3. 对于同一文件，不同对话可能产生不同的处理策略

**技术背景：**
- 现有工具：`python_inter`、`fig_inter`、`load_dataset`、`load_multiheader_excel`
- 沙箱环境：支持 pandas、matplotlib、seaborn
- 当前限制：无动态模型选择能力（LangGraph agent 使用固定模型）

## Goals / non-goals

**Goals：**
1. 提供清晰、可执行的文件分析思维框架（5阶段流程）
2. 为复杂场景提供专家级分析指导文档
3. 确保模型在处理复杂文件时遵循最佳实践
4. 设计可扩展的复杂度评估机制（为未来模型选择做准备）
5. 保持简单文件的处理效率（无额外开销）

**Non-goals：**
1. 不实现自动文件格式转换（用户保留对转换的控制权）
2. 不修改现有工具接口（`python_inter`、`fig_inter` 保持不变）
3. 不强制所有文件使用复杂流程（简单文件走快速路径）
4. 不在第一版实现完整的动态模型切换（设计接口即可）

## Decisions

### 决策 1：5 阶段分析框架

**选择：**采用标准化的 5 阶段分析流程

```
阶段 1：文件初检（File Inspection）
  └─ 读取原始结构（header=None）
  └─ 显示前 10-15 行
  └─ 识别文件基本特征

阶段 2：结构识别（Structure Recognition）
  └─ 识别元信息行、表头行、数据起始行
  └─ 检测多层表头、跨列结构
  └─ 评估复杂度（量化评分）

阶段 3：问题诊断（Problem Diagnosis）
  └─ 列名冲突、缺失、特殊字符
  └─ 数据类型不匹配
  └─ 宽表/长表格式判断

阶段 4：策略制定（Strategy Planning）
  └─ 确定 pandas 参数（header、skiprows）
  └─ 规划数据清洗步骤
  └─ 选择 helper 函数

阶段 5：执行验证（Execution & Validation）
  └─ 执行清洗代码
  └─ 验证列名和数据类型
  └─ 保存清洗后的 DataFrame
```

**理由：**
- 结构化流程强制模型进行系统思考
- 每个阶段有明确的输入/输出和验证点
- 便于调试（可以定位在哪个阶段出错）
- 可扩展（可以在某些阶段插入模型选择逻辑）

**替代方案：**
- ❌ 继续使用平铺式代码示例：缺乏系统性，模型容易跳步
- ❌ 完全自动化流程：丧失灵活性，难以处理边缘情况

### 决策 2：复杂度评分系统

**选择：**实现基于规则的复杂度评分

```python
# 复杂度评估（0-10 分）
score = 0
if has_multiheader: score += 3
if has_cross_column_header: score += 2
if has_metadata_rows: score += 1
if file_size > 10MB: score += 2
if wide_table_format: score += 1
if mixed_data_types: score += 1

# 复杂度等级
# 0-2: 简单（使用快速流程）
# 3-5: 中等（使用标准 5 阶段流程）
# 6+:  复杂（查阅专家指导 + 可选高级模型）
```

**理由：**
- 可解释：用户和开发者都能理解为什么触发复杂流程
- 可调优：阈值可根据实际效果调整
- 低成本：规则判断无需额外模型调用
- 可扩展：未来可替换为 ML 模型评分

**替代方案：**
- ❌ 始终使用复杂流程：浪费资源，降低简单任务效率
- ❌ 让模型自己判断：不可控，可能误判

### 决策 3：分析指导文档设计

**选择：**创建独立的 Markdown 指导文档（`doc/file_analysis_guide.md`）

**内容结构：**
```markdown
# 文件分析专家指导

## 1. Excel 多层表头分析
  - 检查清单（10 个检查点）
  - 常见模式识别
  - Pandas 参数选择矩阵
  - 代码模板

## 2. CSV 编码和分隔符诊断
  - 编码检测流程
  - 分隔符自动推断
  - 错误处理策略

## 3. 宽表/长表转换
  - 识别标准
  - melt 参数指南
  - 性能优化建议

## 4. 常见错误模式库
  - 错误症状 → 根因 → 解决方案
  - 包含真实案例
```

**集成方式：**
- 在 `prompt.py` 中引用文档（"复杂场景请查阅 doc/file_analysis_guide.md"）
- 模型根据复杂度评分决定是否查阅文档
- 未来可考虑将文档嵌入向量数据库实现智能检索

**理由：**
- 保持 prompt.py 简洁（避免过长影响上下文）
- 便于维护和版本控制
- 可以独立更新指导文档而不修改代码
- 支持未来的 RAG 集成

**替代方案：**
- ❌ 全部塞入 prompt.py：超出 token 限制，降低推理质量
- ❌ 使用外部 API 查询：增加延迟和依赖

### 决策 4：模型选择机制（接口设计）

**第一版实现：**仅设计接口，不实现动态切换

```python
# 在 prompt.py 中添加元指令
"""
复杂度评分 ≥6 时的建议：
1. 仔细阅读 doc/file_analysis_guide.md
2. 在阶段 2（结构识别）增加验证步骤
3. 在阶段 4（策略制定）考虑多个方案并评估
4. [预留] 如果配置了高级模型，可在此处切换
"""

# 配置文件接口（暂不实现）
# config/model_strategy.yaml
model_selection:
  enabled: false  # 第一版禁用
  complexity_thresholds:
    simple: 0-2
    medium: 3-5
    complex: 6+
  model_mapping:
    simple: "sonnet-3.5"
    medium: "sonnet-3.5"
    complex: "opus-4"  # 预留
```

**理由：**
- LangGraph 当前可能不支持动态模型切换（需验证）
- 先验证分析框架有效性，再决定是否需要模型切换
- 避免过度设计（可能复杂度提升本身就足够了）

**未来扩展路径：**
1. 收集数据验证高复杂度任务是否需要更强模型
2. 如需要，实现 LangGraph 子图模型选择逻辑
3. 添加成本/性能监控

## Risks / Trade-offs

### 风险 1：Prompt 膨胀导致推理质量下降

**缓解措施：**
- 核心流程精简到 50 行以内（5 阶段 + 复杂度评估）
- 详细内容移至 `doc/file_analysis_guide.md`
- 使用条件引用（"如果复杂度 ≥6，查阅文档"）

### 风险 2：复杂度评分误判

**缓解措施：**
- 保守的阈值设置（宁可多用复杂流程，避免漏判）
- 记录评分日志，便于后续优化
- 允许用户手动指定复杂度级别

### 风险 3：增加简单任务的处理时间

**缓解措施：**
- 快速路径：复杂度 ≤2 直接跳过详细分析
- 延迟检查：只有在遇到错误时才升级到复杂流程
- 性能基准测试确保无退化

### 权衡：灵活性 vs. 自动化

**选择：**偏向灵活性
- 模型生成策略，但需验证（不盲目执行）
- 用户保留对转换逻辑的理解和控制
- 避免"黑盒"自动化导致的不可控结果

## Migration Plan

**阶段 1：非破坏性增强（第 1-2 周）**
- 添加新指导文档和 prompt 章节
- 现有功能保持不变（向后兼容）
- 收集用户反馈

**阶段 2：逐步推广（第 3-4 周）**
- 在复杂文件分析场景推荐使用新流程
- 更新示例和文档
- 监控成功率和用户满意度

**阶段 3：可选优化（第 5+ 周）**
- 根据数据决定是否实现模型选择
- 优化复杂度评分算法
- 集成向量数据库（如果需要）

**回滚计划：**
- 新功能全部在 prompt 可选章节和独立文档
- 可随时删除相关章节恢复原状
- 无数据库 schema 变更，无破坏性修改

## Open Questions

1. **LangGraph 是否支持条件模型选择？**
   - 需要验证：子图是否可以配置不同的 LLM？
   - 如果不支持，模型选择功能暂时作为"建议"而非强制

2. **复杂度阈值应该设置为多少？**
   - 建议：通过 A/B 测试确定最优阈值
   - 初始值：3 分触发标准流程，6 分触发专家指导

3. **是否需要向量数据库检索指导文档？**
   - 第一版：手动引用 Markdown 文档
   - 未来：如果文档超过 5000 字，考虑 RAG

4. **如何收集模型分析质量的指标？**
   - 建议：记录复杂度评分、是否查阅文档、最终成功/失败
   - 用于后续优化和验证模型选择是否必要
